import json
import time
import os
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

# ==========================================
# [ì„¤ì •]
# ==========================================
TARGET_URL = "https://www.metatft.com/comps"
OUTPUT_FILE = "data/metatft_comps_final.json"

def clean_text(text):
    if not text: return ""
    return text.strip().replace("\n", " ").replace("\r", "")

def crawl_metatft():
    chrome_options = Options()
    chrome_options.page_load_strategy = 'normal' # ë¡œë”© í™•ì‹¤í•˜ê²Œ
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36")

    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
    
    deck_list = []
    # [ì¶”ê°€ëœ ë¶€ë¶„ 1] ì¤‘ë³µ ì²´í¬ë¥¼ ìœ„í•œ ì§‘í•©(Set) ì´ˆê¸°í™”
    seen_decks = set()

    try:
        print(f">>> MetaTFT ì ‘ì† ì‹œë„: {TARGET_URL}")
        driver.get(TARGET_URL)

        # ---------------------------------------------------------
        # [Step 1] ì ì§„ì  ìŠ¤í¬ë¡¤ (Incremental Scroll)
        # ---------------------------------------------------------
        print(">>> ë°ì´í„°ë¥¼ ë†“ì¹˜ì§€ ì•Šê¸° ìœ„í•´ ì²œì²œíˆ ìŠ¤í¬ë¡¤í•©ë‹ˆë‹¤...")
        
        # ì´ˆê¸° ë¡œë”© ëŒ€ê¸°
        try:
            WebDriverWait(driver, 20).until(
                EC.presence_of_element_located((By.CLASS_NAME, "Stat_Number"))
            )
        except:
            print("   (ê²½ê³ : ì´ˆê¸° ë¡œë”©ì´ ëŠ¦ìŠµë‹ˆë‹¤)")

        # í˜„ì¬ ìŠ¤í¬ë¡¤ ìœ„ì¹˜
        current_position = 0
        # í•œ ë²ˆì— ë‚´ë¦´ ë†’ì´ (ëª¨ë‹ˆí„° ë†’ì´ ì •ë„)
        scroll_step = 900 
        
        while True:
            # 1. ìŠ¤í¬ë¡¤ì„ ì¡°ê¸ˆ ë‚´ë¦¼
            driver.execute_script(f"window.scrollBy(0, {scroll_step});")
            current_position += scroll_step
            
            # 2. ì¤‘ê°„ ë¡œë”© ëŒ€ê¸° (ì´ ì‹œê°„ì´ ìˆì–´ì•¼ ì¤‘ê°„ ë°ì´í„°ê°€ ë Œë”ë§ë¨)
            time.sleep(1.5) 
            
            # 3. í˜ì´ì§€ ëì— ë„ë‹¬í–ˆëŠ”ì§€ í™•ì¸
            total_height = driver.execute_script("return document.body.scrollHeight")
            visible_height = driver.execute_script("return window.innerHeight")
            
            # í˜„ì¬ ìœ„ì¹˜ê°€ ì „ì²´ ë†’ì´ë³´ë‹¤ í¬ê±°ë‚˜ ê°™ìœ¼ë©´ ì¢…ë£Œ
            if current_position + visible_height >= total_height:
                # í˜¹ì‹œ ëª¨ë¥´ë‹ˆ ëì—ì„œ í•œ ë²ˆ ë” ëŒ€ê¸°í•˜ê³  ë†’ì´ ì¬í™•ì¸ (ë¬´í•œ ìŠ¤í¬ë¡¤ ëŒ€ë¹„)
                time.sleep(2)
                new_total_height = driver.execute_script("return document.body.scrollHeight")
                if new_total_height == total_height:
                    print(">>> í˜ì´ì§€ ë ë„ë‹¬ ì™„ë£Œ!")
                    break
                else:
                    total_height = new_total_height # í˜ì´ì§€ê°€ ë” ê¸¸ì–´ì¡Œìœ¼ë©´ ê³„ì† ì§„í–‰

            print(f"   ... ìŠ¤í¬ë¡¤ ì§„í–‰ ì¤‘ ({current_position}/{total_height})")

        # ---------------------------------------------------------
        # [Step 2] HTML íŒŒì‹±
        # ---------------------------------------------------------
        print(">>> ì „ì²´ HTML íŒŒì‹± ì‹œì‘...")
        soup = BeautifulSoup(driver.page_source, "html.parser")
        
        # Placeholderì™€ ê´‘ê³  ì œì™¸
        rows = soup.find_all("div", class_=lambda x: x and "CompRow" in x and "CompRowPlaceholder" not in x)
        
        print(f">>> ìœ íš¨ ë± {len(rows)}ê°œ ë°œê²¬. ë°ì´í„° ì¶”ì¶œ ë° ì¤‘ë³µ ì œê±° ì‹œì‘...")

        valid_count = 0
        duplicate_count = 0 # ì¤‘ë³µ ì¹´ìš´íŠ¸
        
        for idx, row in enumerate(rows):
            try:
                # --- A. ê¸°ë³¸ ì •ë³´ ---
                tier_badge = row.select_one(".CompRowTierBadge")
                tier = clean_text(tier_badge.get_text()) if tier_badge else "Unknown"

                name_div = row.select_one(".Comp_Title")
                deck_name = clean_text(name_div.get_text()) if name_div else ""

                tags = [clean_text(tag.get_text()) for tag in row.select(".CompRowTag")]

                # [ì¶”ê°€ëœ ë¶€ë¶„ 2] ì¤‘ë³µ ì œê±° ë¡œì§
                # ë± ì‹ë³„ í‚¤ ìƒì„±: (í‹°ì–´, ë±ì´ë¦„, íƒœê·¸ë“¤)
                # íƒœê·¸ ìˆœì„œê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì •ë ¬í•˜ì—¬ íŠœí”Œë¡œ ë³€í™˜
                deck_identifier = (tier, deck_name, tuple(sorted(tags)))

                if deck_identifier in seen_decks:
                    # ì´ë¯¸ ìˆ˜ì§‘ëœ ë±ì´ë©´ ê±´ë„ˆëœ€
                    duplicate_count += 1
                    continue
                
                # ìƒˆë¡œìš´ ë±ì´ë©´ ì‹ë³„ í‚¤ ë“±ë¡
                seen_decks.add(deck_identifier)

                # --- B. í†µê³„ ì •ë³´ ---
                def get_stat_value(label):
                    # í…ìŠ¤íŠ¸ë¡œ ì°¾ê³  -> ë‹¤ìŒ ìˆ«ì ì°¾ê¸°
                    stat_label = row.find("span", string=lambda text: text and label in text)
                    if stat_label:
                        # find_nextëŠ” DOM íŠ¸ë¦¬ ìˆœì„œìƒ ë’¤ì— ìˆëŠ” ìš”ì†Œë¥¼ ì°¾ìŒ
                        number_el = stat_label.find_next(class_="Stat_Number")
                        if number_el:
                            val = clean_text(number_el.get_text())
                            return val if val else "-"
                    return "-"

                avg_place = get_stat_value("Avg Place")
                win_rate = get_stat_value("Win Rate")
                top4_rate = get_stat_value("Top 4 Rate")
                
                # ê²€ì¦: í†µê³„ê°€ ì—†ìœ¼ë©´ ê»ë°ê¸°ë¡œ ê°„ì£¼í•˜ê³  íŒ¨ìŠ¤
                if avg_place == "-" and win_rate == "-":
                    continue

                # --- C. ì±”í”¼ì–¸ ---
                champions = []
                unit_wrappers = row.select(".Unit_Wrapper")
                
                for unit in unit_wrappers:
                    if unit.select_one(".UnitFiller"): continue

                    # ì´ë¦„
                    champ_name = ""
                    name_el = unit.select_one(".UnitNames")
                    if name_el:
                        champ_name = clean_text(name_el.get_text())
                    
                    if not champ_name:
                        link_el = unit.find("a", href=True)
                        if link_el:
                            champ_name = link_el['href'].split("/")[-1].replace("%20", " ")
                        else:
                            img_el = unit.select_one(".Unit_img")
                            if img_el:
                                champ_name = img_el.get("alt", "Unknown")

                    # ì•„ì´í…œ
                    items = []
                    for item_img in unit.select(".ItemsContainer_Inline img.Item_img"):
                        item_alt = item_img.get('alt')
                        if item_alt:
                            items.append(item_alt)

                    # ë³„ ë ˆë²¨ (3ì„±)
                    star_level = 2
                    stars_div = unit.select_one(".stars_div")
                    if stars_div and stars_div.find("img"):
                        star_level = 3
                    
                    champions.append({
                        "name": champ_name,
                        "star": star_level,
                        "items": items
                    })

                if not champions: continue

                # ë± ì´ë¦„ ìë™ ìƒì„± (ì—†ì„ ê²½ìš°)
                if not deck_name or deck_name == "Unknown Deck":
                    carries = [c['name'] for c in champions if len(c['items']) >= 2]
                    if not carries: carries = [champions[0]['name']]
                    deck_name = f"{' & '.join(carries)} Deck"

                deck_data = {
                    "tier": tier,
                    "name": deck_name,
                    "tags": tags,
                    "avg_place": avg_place,
                    "win_rate": win_rate,
                    "top4_rate": top4_rate,
                    "champions": champions
                }
                deck_list.append(deck_data)
                valid_count += 1

            except Exception as e:
                print(f"âš ï¸ Row Parsing Error: {e}")
                continue

        # 4. ì €ì¥
        if not os.path.exists("data"):
            os.makedirs("data")

        with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
            json.dump(deck_list, f, indent=4, ensure_ascii=False)

        print(f"\nâœ… [MetaTFT] ìµœì¢… ì •ì œ ì™„ë£Œ!")
        print(f"   - ì „ì²´ ë°œê²¬ í–‰: {len(rows)}")
        print(f"   - ì¤‘ë³µ ì œê±°ë¨: {duplicate_count}")
        print(f"   - ìµœì¢… ì €ì¥: {valid_count}")
        print(f"ğŸ“„ ì €ì¥ ê²½ë¡œ: {OUTPUT_FILE}")
        
    except Exception as e:
        print(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
    finally:
        driver.quit()

if __name__ == "__main__":
    crawl_metatft()