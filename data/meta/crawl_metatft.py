import json
import time
import os
import re
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

# ==========================================
# [ì„¤ì •]
# ==========================================
TARGET_URL = "https://www.metatft.com/comps"
OUTPUT_FILE = "data/meta/metatft_comps_final.json"

def clean_text(text):
    if not text: return ""
    return text.strip().replace("\n", " ").replace("\r", "")

def crawl_metatft():
    chrome_options = Options()
    
    # â˜… [í•µì‹¬ 1] í˜ì´ì§€ ë¡œë“œ ì „ëµ ë³€ê²½: 'normal'(ê¸°ë³¸ê°’) -> 'eager'
    # eager: ì´ë¯¸ì§€/ê´‘ê³  ë¡œë”© ì•ˆ ê¸°ë‹¤ë¦¼. HTMLë§Œ ëœ¨ë©´ ë°”ë¡œ ì§„í–‰.
    chrome_options.page_load_strategy = 'eager' 
    
    # ì°½ í¬ê¸° ì„¤ì •
    chrome_options.add_argument("--window-size=1920,1080")
    
    # ë´‡ íƒì§€ íšŒí”¼ (ê¸°ë³¸ì ì¸ ê²ƒë§Œ)
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")

    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
    
    deck_list = []
    seen_decks = set()

    try:
        print(f">>> MetaTFT ì ‘ì† (Fast Mode): {TARGET_URL}")
        driver.get(TARGET_URL)

        # â˜… [í•µì‹¬ 2] ë¬´í•œ ë¡œë”© ëŠê¸°
        # ì‚¬ì´íŠ¸ ì „ì²´ ë¡œë”©ì„ ê¸°ë‹¤ë¦¬ì§€ ì•Šê³ , ë± ì •ë³´(.CompRow)ê°€ í•˜ë‚˜ë¼ë„ ë³´ì´ë©´ ë°”ë¡œ ë©ˆì¶¤
        try:
            print(">>> í•µì‹¬ ë°ì´í„° ëŒ€ê¸° ì¤‘...")
            WebDriverWait(driver, 15).until(
                EC.presence_of_element_located((By.CLASS_NAME, "CompRow"))
            )
            # ê°•ì œë¡œ ë‚˜ë¨¸ì§€ ë¡œë”©(ê´‘ê³  ë“±) ì¤‘ë‹¨ì‹œí‚´
            driver.execute_script("window.stop();")
            print(">>> ë¡œë”© ê°•ì œ ì¤‘ë‹¨ ë° ìŠ¤í¬ë¡¤ ì‹œì‘!")
        except Exception as e:
            print(">>> ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼ (ë°ì´í„°ê°€ ì—†ì„ ìˆ˜ë„ ìˆìŒ)")

        # ---------------------------------------------------------
        # ìŠ¤í¬ë¡¤ ë¡œì§ (ë¹ ë¥´ê²Œ)
        # ---------------------------------------------------------
        current_position = 0
        scroll_step = 1000 
        max_scroll_attempts = 20
        scroll_count = 0

        while scroll_count < max_scroll_attempts:
            driver.execute_script(f"window.scrollBy(0, {scroll_step});")
            current_position += scroll_step
            scroll_count += 1
            
            # eager ëª¨ë“œë¼ ë Œë”ë§ ì‹œê°„ì´ ì¡°ê¸ˆ í•„ìš”í•  ìˆ˜ ìˆìŒ (1ì´ˆë©´ ì¶©ë¶„)
            time.sleep(1)
            
            total_height = driver.execute_script("return document.body.scrollHeight")
            visible_height = driver.execute_script("return window.innerHeight")
            
            if current_position + visible_height >= total_height:
                time.sleep(1) # ëì—ì„œ ì ê¹ ëŒ€ê¸°
                if driver.execute_script("return document.body.scrollHeight") <= total_height + 100:
                    break

        # ---------------------------------------------------------
        # ë°ì´í„° ì¶”ì¶œ
        # ---------------------------------------------------------
        print(">>> ë°ì´í„° ì¶”ì¶œ ì¤‘...")
        soup = BeautifulSoup(driver.page_source, "html.parser")
        
        rows = soup.find_all("div", class_=lambda x: x and "CompRow" in x and "CompRowPlaceholder" not in x)
        print(f">>> ë°œê²¬ëœ ë±: {len(rows)}ê°œ")

        for row in rows:
            try:
                # 1. ê¸°ë³¸ ì •ë³´
                tier_badge = row.select_one(".CompRowTierBadge")
                tier = clean_text(tier_badge.get_text()) if tier_badge else "Unknown"
                name_div = row.select_one(".Comp_Title")
                deck_name = clean_text(name_div.get_text()) if name_div else ""
                tags = [clean_text(tag.get_text()) for tag in row.select(".CompRowTag")]

                # ì¤‘ë³µ ì²´í¬
                deck_identifier = (tier, deck_name, tuple(sorted(tags)))
                if deck_identifier in seen_decks: continue
                seen_decks.add(deck_identifier)

                # 2. í†µê³„ ì •ë³´
                def get_stat_value(label):
                    stat_label = row.find("span", string=lambda text: text and label in text)
                    if stat_label:
                        number_el = stat_label.find_next(class_="Stat_Number")
                        if number_el:
                            return clean_text(number_el.get_text())
                    return "-"

                avg_place = get_stat_value("Avg Place")
                win_rate = get_stat_value("Win Rate")
                top4_rate = get_stat_value("Top 4 Rate")
                
                if avg_place == "-" and win_rate == "-": continue

                # 3. ì±”í”¼ì–¸ & ì•„ì´í…œ
                champions = []
                unit_wrappers = row.select(".Unit_Wrapper")
                for unit in unit_wrappers:
                    if unit.select_one(".UnitFiller"): continue
                    
                    champ_name = ""
                    name_el = unit.select_one(".UnitNames")
                    if name_el: champ_name = clean_text(name_el.get_text())
                    
                    if not champ_name:
                        img_el = unit.select_one(".Unit_img")
                        if img_el: champ_name = img_el.get("alt", "Unknown")

                    items = [img.get('alt') for img in unit.select(".ItemsContainer_Inline img.Item_img") if img.get('alt')]
                    star = 3 if unit.select_one(".stars_div img") else 2
                    
                    champions.append({"name": champ_name, "star": star, "items": items})
                
                if not champions: continue

                # 4. [ì‹œë„ˆì§€ ì¶”ì¶œ]
                synergies = []
                trait_elements = row.select(".CompUnitTraitsContainer .TraitCompact")
                for trait in trait_elements:
                    # ê°œìˆ˜ (4, 2 ë“±)
                    count = clean_text(trait.get_text())
                    
                    # ìŠ¤íƒ€ì¼ (gold, silver ë“±)
                    style = "Normal"
                    for cls in trait.get("class", []):
                        if cls in ["bronze", "silver", "gold", "platinum", "chromatic", "unique"]:
                            style = cls
                            break
                    
                    # ì´ë¦„ (ì´ë¯¸ì§€ URL íŒŒì‹±)
                    trait_name = "Unknown"
                    icon_div = trait.select_one(".TraitCompactIconContainer")
                    if icon_div and icon_div.has_attr("style"):
                        # style="mask-image: url('.../traits/sorcerer.png');"
                        match = re.search(r'traits/([^/]+)\.png', icon_div["style"])
                        if match:
                            trait_name = match.group(1).replace("%20", " ").title()
                    
                    synergies.append({"name": trait_name, "count": count, "style": style})

                # 5. ë± ì´ë¦„ ìƒì„±
                if not deck_name or deck_name == "Unknown Deck":
                    carries = [c['name'] for c in champions if len(c['items']) >= 2]
                    if not carries and champions: carries = [champions[0]['name']]
                    deck_name = f"{' & '.join(carries)} Deck"

                deck_list.append({
                    "tier": tier,
                    "name": deck_name,
                    "tags": tags,
                    "avg_place": avg_place,
                    "win_rate": win_rate,
                    "top4_rate": top4_rate,
                    "synergies": synergies,
                    "champions": champions
                })

            except Exception as e:
                continue

        # ì €ì¥
        if not os.path.exists("data"): os.makedirs("data")
        with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
            json.dump(deck_list, f, indent=4, ensure_ascii=False)

        print(f"\nâœ… ì™„ë£Œ! ì´ {len(deck_list)}ê°œ ë± ìˆ˜ì§‘ë¨.")
        print(f"ğŸ“„ ì €ì¥ ê²½ë¡œ: {OUTPUT_FILE}")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        driver.quit()

if __name__ == "__main__":
    crawl_metatft()