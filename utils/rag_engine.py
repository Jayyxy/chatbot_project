# utils/rag_engine.py

import json
import os
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain_core.documents import Document
from langchain_core.runnables import RunnableLambda # â˜… ì¶”ê°€ë¨: ì»¤ìŠ¤í…€ ê²€ìƒ‰ê¸°ìš©

from dotenv import load_dotenv
load_dotenv()

if not os.environ.get("OPENAI_API_KEY"):
    print("âŒ [ì˜¤ë¥˜] OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤! .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
else:
    print("âœ… [ì„±ê³µ] API Key ë¡œë“œ ì™„ë£Œ")

# ê²½ë¡œ ì„¤ì •
DECK_FILE = "data/meta/merged_decks.json"
ITEM_FILE = "data/item/lolchess_items.json"
CHAMP_FILE = "data/champion/champion_data.json"

# =================================================================
# [1] ì „ì—­ ë°ì´í„° ë¡œë“œ (í‚¤ì›Œë“œ ê²€ìƒ‰ìš© Raw Data)
# =================================================================
# ë¬¸ì„œë¥¼ ë§¤ë²ˆ ë¡œë“œí•˜ì§€ ì•Šê³  ë©”ëª¨ë¦¬ì— ìºì‹±í•´ë‘¡ë‹ˆë‹¤.
RAW_DECKS = []
if os.path.exists(DECK_FILE):
    with open(DECK_FILE, "r", encoding="utf-8") as f:
        RAW_DECKS = json.load(f)

def load_data_as_documents():
    """ë²¡í„° DB ìƒì„±ì„ ìœ„í•œ ë¬¸ì„œ(Document) ë¦¬ìŠ¤íŠ¸ ë³€í™˜"""
    docs = []
    
    # 1. ë± ë°ì´í„° (RAW_DECKS í™œìš©)
    for d in RAW_DECKS:
        champs = ", ".join([c["name"] for c in d.get("champions", [])])
        # â˜… ê²€ìƒ‰ ì •í™•ë„ë¥¼ ìœ„í•´ ì‹œë„ˆì§€ ì •ë³´ë„ í…ìŠ¤íŠ¸ì— í¬í•¨
        synergies = ", ".join([f"{s['name']}({s['count']})" for s in d.get("synergies", [])])
        
        content = f"""
        [ë± ì •ë³´]
        ì´ë¦„: {d.get('name_kr', d.get('name'))}
        í‹°ì–´: {d.get('tier', '-')} | ìŠ¹ë¥ : {d.get('win_rate', '-')} | í‰ê· ë“±ìˆ˜: {d.get('avg_place', '-')}
        HOT: {d.get('is_hot')}
        ì‹œë„ˆì§€: {synergies}
        ì±”í”¼ì–¸: {champs}
        ê°€ì´ë“œ: {d.get('guide', {})}
        """
        docs.append(Document(page_content=content, metadata={"type": "deck"}))

    # 2. ì•„ì´í…œ ë°ì´í„°
    if os.path.exists(ITEM_FILE):
        with open(ITEM_FILE, "r", encoding="utf-8") as f:
            items = json.load(f)
        for i in items:
            content = f"[ì•„ì´í…œ ì •ë³´] ì´ë¦„: {i['name']} \nì¡°í•©: {', '.join(i.get('recipe', []))} \níš¨ê³¼: {i.get('effect')}"
            docs.append(Document(page_content=content, metadata={"type": "item"}))

    # 3. ì±”í”¼ì–¸ ë°ì´í„°
    if os.path.exists(CHAMP_FILE):
        with open(CHAMP_FILE, "r", encoding="utf-8") as f:
            champs_data = json.load(f)
        for c in champs_data:
            content = f"""
            [ì±”í”¼ì–¸ ì •ë³´]
            ì´ë¦„: {c.get('name')}
            ë¹„ìš©: {c.get('cost')}ì½”ìŠ¤íŠ¸
            íŠ¹ì„±: {', '.join(c.get('traits', []))}
            í‹°ì–´: {c.get('tier')}
            ì¶”ì²œí…œ: {', '.join(c.get('popular_items', []))}
            """
            docs.append(Document(page_content=content, metadata={"type": "champion", "name": c.get('name')}))
            
    return docs

# =================================================================
# [2] í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë¡œì§ (í‚¤ì›Œë“œ + ë²¡í„°)
# =================================================================
def build_retriever():
    """
    ë²¡í„° ê²€ìƒ‰(ìœ ì‚¬ë„)ê³¼ í‚¤ì›Œë“œ ê²€ìƒ‰(ì •í™•ë„)ì„ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # 1. ë²¡í„° ì €ì¥ì†Œ ë¹Œë“œ (ê¸°ì¡´ ë¡œì§)
    docs = load_data_as_documents()
    if not docs: return None
    
    embeddings = OpenAIEmbeddings()
    vectorstore = FAISS.from_documents(docs, embeddings)
    base_retriever = vectorstore.as_retriever(search_kwargs={"k": 3}) # ë²¡í„°ëŠ” ìƒìœ„ 3ê°œë§Œ

    # 2. í‚¤ì›Œë“œ ê²€ìƒ‰ í•¨ìˆ˜ ì •ì˜
    def keyword_search_decks(query):
        """ì§ˆë¬¸ì— í¬í•¨ëœ ì±”í”¼ì–¸/ë± ì´ë¦„ì´ ìˆìœ¼ë©´ í•´ë‹¹ ë±ì„ ê°•ì œë¡œ ì°¾ì•„ëƒ…ë‹ˆë‹¤."""
        matched_docs = []
        query = query.replace(" ", "") # ë„ì–´ì“°ê¸° ë¬´ì‹œ (ì˜ˆ: ë°€ë¦¬ì˜¤ë± -> ë°€ë¦¬ì˜¤)
        
        for d in RAW_DECKS:
            # ê²€ìƒ‰ ì¡°ê±´: ë± ì´ë¦„(KR) ë˜ëŠ” ì±”í”¼ì–¸ ë¦¬ìŠ¤íŠ¸ì— ê²€ìƒ‰ì–´ê°€ í¬í•¨ë˜ëŠ”ê°€?
            deck_name = d.get('name_kr', '').replace(" ", "")
            champ_names = [c['name'] for c in d.get('champions', [])]
            
            is_match = False
            # 1) ë± ì´ë¦„ ë§¤ì¹­
            if deck_name and deck_name in query:
                is_match = True
            # 2) ì±”í”¼ì–¸ ì´ë¦„ ë§¤ì¹­
            else:
                for c_name in champ_names:
                    if c_name in query: # ì˜ˆ: query="ë°€ë¦¬ì˜¤ë±ì¶”ì²œ", c_name="ë°€ë¦¬ì˜¤"
                        is_match = True
                        break
            
            if is_match:
                # Document í˜•íƒœë¡œ ë³€í™˜ (load_data_as_documentsì™€ í˜•ì‹ í†µì¼)
                champs = ", ".join([c["name"] for c in d.get("champions", [])])
                synergies = ", ".join([f"{s['name']}({s['count']})" for s in d.get("synergies", [])])
                content = f"""
                [ë± ì •ë³´ (í‚¤ì›Œë“œ ë§¤ì¹­ë¨)]
                ì´ë¦„: {d.get('name_kr', d.get('name'))}
                í‹°ì–´: {d.get('tier', '-')} | ìŠ¹ë¥ : {d.get('win_rate', '-')}
                ì‹œë„ˆì§€: {synergies}
                ì±”í”¼ì–¸: {champs}
                ê°€ì´ë“œ: {d.get('guide', {})}
                """
                matched_docs.append(Document(page_content=content, metadata={"type": "deck", "source": "keyword"}))
        
        return matched_docs

    # 3. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰ í•¨ìˆ˜ (RunnableLambdaìš©)
    def hybrid_search(query):
        # A. í‚¤ì›Œë“œë¡œ ë± ì°¾ê¸° (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
        keyword_results = keyword_search_decks(query)
        
        # B. ë²¡í„°ë¡œ ì˜ë¯¸ ê²€ìƒ‰ (ë³´ì¡°)
        vector_results = base_retriever.invoke(query)
        
        # C. ê²°ê³¼ ë³‘í•© (ì¤‘ë³µ ì œê±° ë¡œì§ì€ ê°„ë‹¨íˆ ìƒëµ, í‚¤ì›Œë“œ ê²°ê³¼ê°€ ì•ì— ì˜¤ë„ë¡)
        # í‚¤ì›Œë“œë¡œ ì°¾ì€ê²Œ ìˆìœ¼ë©´ ê·¸ê±¸ ìµœìš°ì„ ìœ¼ë¡œ ë³´ì—¬ì¤Œ
        if keyword_results:
            print(f"ğŸ” [Hybrid] í‚¤ì›Œë“œ ë§¤ì¹­ ì„±ê³µ: {len(keyword_results)}ê°œ ë±")
            return keyword_results + vector_results
        
        return vector_results

    # LangChain ì²´ì¸ì— ë°”ë¡œ ë¼ìš¸ ìˆ˜ ìˆë„ë¡ Runnableë¡œ ë°˜í™˜
    return RunnableLambda(hybrid_search)